###############################################
## Load LiPD files
## The main part of loading the the data to
## memory
###############################################

#' Import the data from each csv and jsonld file for given LiPDs
#' @export
#' @keywords internal
#' @param tmp Char path to the temp folder in memory
#' @param files_noext List of lipd files without extention
#' @return out.list List of data for each lipd file
loadLipdFiles <- function(tmp, files_noext){

  # Move into the tmp folder
  setwd(tmp)

  out.list <- list()
  file.count <- length(files_noext)

  for(i in 1:file.count){
    current <- files_noext[[i]]
    print(sprintf("loading: %s", current))
    tryCatch({
      setwd(current)

      # real bagit. move into data folder
      if (dir.exists("data")){ setwd("data") }

      # fake bagit. no data folder. all files in root dir.
      data.list <- getData()

      # compiled list of all data
      out.list[[files_noext[[i]]]] <- data.list

      # Move back up to the tmp directory
      setwd(tmp)
    },error=function(cond){
      print("Couldn't find the unarchived LiPD data. Make sure your LiPD filename matches the data set name. ")
    })

  }
  return(out.list)
}

#' Retrieve and import csv and jsonld files in the current directory.
#' @export
#' @keywords internal
#' @return data.list List of data for one LiPD file
getData <- function(){
  data.list <- list()
  # list of csv files
  c <- listFiles("csv")
  # csv data placeholder
  c.data=vector(mode="list",length=length(c))
  # import each csv file
  for (ci in 1:length(c)){
    df=read.csv(c[ci], header=FALSE, blank.lines.skip = FALSE,na.strings = c("nan", "NaN", "NAN", "NA"))
    c.data[[c[ci]]]=df
  }

  # jsonld file - one per lpd
  j <- listFiles("jsonld")
  # import jsonld file
  j.data <- jsonlite::fromJSON(j, simplifyDataFrame = FALSE)

  # combine data for return.
  data.list[["metadata"]] <- j.data
  data.list[["csv"]] <- c.data
  # data.list[["csv"]] <- clean.csv(data.list[["csv"]])

  return(data.list)
}
